{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 28801     \n",
      "=================================================================\n",
      "Total params: 269,633\n",
      "Trainable params: 269,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=40,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "\n",
    "base_dir = 'dogs-vs-cats-small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                  train_dir,\n",
    "                                    target_size=(150, 150),\n",
    "                                    batch_size=20,\n",
    "                                    class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khan\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.6927 - acc: 0.5050\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.6960 - acc: 0.4800\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.6936 - acc: 0.4850\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.6941 - acc: 0.4800\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.6939 - acc: 0.4850\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=2e-5),metrics=['acc'])\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=10,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "img_path = 'cat.1.jpg'\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05974574]]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_output = model.output[:, 0]\n",
    "last_conv_layer = model.get_layer('conv2d_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "grads = K.gradients(cat_output, last_conv_layer.output)[0]\n",
    "pooled_grads =  K.mean(grads, axis=(0, 1, 2))\n",
    "iterate = K.function([model.input],[pooled_grads, last_conv_layer.output[0]])\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "for i in range(128):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2872a146978>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('cat.1.jpg')\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('cat_cam.png', superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
